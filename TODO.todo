Controllare e sistemare lo pseudo codice con tutto aggiornato e magari guardare come è fatto quello BDI standard per confrontare.

Testare:
- Stateless intention generation devo solo modificare la funzione manager.get_library() per includere solo le azioni base
- No desire triggering semplicemente non chiamo la prima parte in nel loop in control
- A quanto pare la mia idea che il desire può essere eseguito utilizzando tutte le intenzioni che contiene è sbagliata, sembrerebbe che sia sufficiente eseguire solamente l'ultima intenzione che scrive, cambiato in run_desire nel manager
- desire implementati listati nella control question 1
- desire trigger evaluation se è positiva o negativa per supportare l'ambiente che cambia nel tempo
- testare invalidazione di called intentions dopo 3 valutazioni negative (per gestire cambiamenti dell'ambiente)


1: moveup, 2: movedown, 3: moveleft, 4: moveright, 5: pickup, 6: putdown


Ho bisogno di fare in modo che il belief set sia modificabile in tempo real dalla perception unit. E devo poter eseguire il piano man mano che le intention lo generano.

Un problema è che se prima testavo la intention, ora non posso farlo perché può essere che la logica della funzione si basa su un belief set che si modifica. E quindi devo testare direttamente runnando le azioni generate. Quindi niente più test_intention. Posso solo controllare che la funzione sia effettivmanete valida in python.
E il problema di mandare il runtime error alla LLM per provare a sistemare la funzione non è nemmeno possibile perché magari alcune azioni le ha eseguite e quindi alcuni eventi me li perdo. Insomma è un casino, eviterei di fare testing delle funzioni e se avvengono errori semplicemente non provo a correggere e genero la prossima intention.
Anche il testare le funzioni già in libreria non è più possibile perché avrei bisogno di eseguire le azioni che generano. E quindi devo farmi bastare il meccanismo che se una intention viene usata da una nuova funzione per tre volte di fila ma la intention generata fallisce sempre, allora quella funzione viene rimossa.
Però come faccio se una funzione già in libreria da errore? Boh direi che vale sempre il meccanismo del se fallisce 3 volte di fila una nuvoa intention che contiene una chiamata a quella già in libreria allora quella in libreria viene tolta. Anche se dovesse avvenire un errore a runtime vale lo stesso la regola. Devo controllare che questa cosa valga non solo quando la evaluation è negativa.

Devo ricordarmi di cambiare nel prompt le istruzione per usare e creare funzioni. Ora invece di prendere in input il belief_set, le funzioni lo utilizzano come variabile globale. Quindi devo dare l'esempio di come cominciare la funzione.
# posso indicare di cominciare la funzione con 
# def function():
#     global belief_set
#     ...

Aumentare il numero di tentativi per le intention da 3 a 5?

Mi sono accorto che uno dei problemi che potrebbero accadere è che vado a leggere il belief set prima che le perception function lo vadano ad aggiornare con gli eventi appena ricevuti. Quindi ogni volta che uso la funzione get_belief_set() in control devo verificare se questo potrebbe essere un problema ed eventualmente aggiungere un time.sleep(0.2) ad esempio. Ho appena controllato e questo non è un problema perché tutte le volte che mi interessa andare a vedere il belief set è quando ho appena eseguito una azione e aspettato 0.2 per ricevere gli eventi, perciò il belief set è già aggiornato. Sia nel runnare un desire che una intention.



Aggiungere un meccanismo che permette di rifare da zero il belief set? Salvando magari gli ultimi n eventi per ogni object type, e con dei prompt apposta che capiscono come è meglio ristrutturare il belief set ora che hanno un esempio di belief set.



Creare stima di costo per esperimento?

Per avere i replay della finestra di pygame, potrei utilizzare seed per riprodurre le stesse generazioni di elementi casuali, e per le azioni invece posso salvare lato server le azioni che ricevo da ogni agente in quale frame sono state ricevute e poi nel replay simulare la loro ricezione, utilizzando già l'architettura che ho nel file server.py.

Idealmente vorrei un ambiente con pochi elementi, per evitare di creare complessità inutile, e per tenere la lunghezza dei prompt bassa. Quindi mappa piccola, basso spawn rate delle parcelle, decay lento o nullo, magari con punteggio basso delle parcelle.

Rivedere desire evaluation e aggiungere altre informazioni, magari riguardanti le intention eseguite, o solo l'ultima con la sua descrizione?




Provare a vedere se cambiare la temperature per la request cambia le cose.

Cambiare nel prompting il self.stop quando pronto per esperimenti.

Per poter runnare il progetto serve: pygame, astor, python-dotenv, PyQt5, openai e ovviamente il file .env con le variablili di ambiente. Aggiornare magari la descrizione della repo così da spiegare come farlo partire.

https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/


Cose di cui parlare:
- a che punto sono con il progetto
- nuovo meccanismo della memoria dato dal problema della conoscenza dell'utente sulle azioni e come modificano l'ambiente (ed eventi)
- come eseguire gli esperimenti
- mostrare esempio di esperimento
- modello di azure

Note su incontro:
evoluzione dell'ambiente con cambiamenti della mappa, o aggiunta di nuovi elementi

provare senza score, o con delivery zones che danno più punti

capire se ci possono essere evoluzioni diverse con lo stesso gioco, capire se ci sono diverse direzioni di evoluzione

reward negativo per azioni sbagliate