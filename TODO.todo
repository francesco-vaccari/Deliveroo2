Testare:
- Stateless intention generation devo solo modificare la funzione manager.get_library() per includere solo le azioni base
- No desire triggering semplicemente non chiamo la prima parte in nel loop in control
- A quanto pare la mia idea che il desire può essere eseguito utilizzando tutte le intenzioni che contiene è sbagliata, sembrerebbe che sia sufficiente eseguire solamente l'ultima intenzione che scrive, cambiato in run_desire nel manager
- desire implementati listati nella control question 1
- desire trigger evaluation se è positiva o negativa per supportare l'ambiente che cambia nel tempo
- testare invalidazione di called intentions dopo 3 valutazioni negative (per gestire cambiamenti dell'ambiente)
- no evaluation of desires triggered


1: moveup, 2: movedown, 3: moveleft, 4: moveright, 5: pickup, 6: putdown


Specificare meglio che il belief set è aggiornato mano a mano che le azioni vengono eseguite?

Aumentare il numero di tentativi per le intention da 3 a 5?

Provare a vedere se cambiare la temperature per la request cambia le cose?

Per poter runnare il progetto serve: pygame, astor, python-dotenv, PyQt5, openai e ovviamente il file .env con le variablili di ambiente. Aggiornare magari la descrizione della repo così da spiegare come farlo partire.


Cose di cui parlare:
- a che punto sono con il progetto
- nuovo meccanismo della memoria dato dal problema della conoscenza dell'utente sulle azioni e come modificano l'ambiente (ed eventi)
- come eseguire gli esperimenti
- mostrare esempio di esperimento
- modello di azure

Note su incontro:
evoluzione dell'ambiente con cambiamenti della mappa, o aggiunta di nuovi elementi

provare senza score, o con delivery zones che danno più punti

capire se ci possono essere evoluzioni diverse con lo stesso gioco, capire se ci sono diverse direzioni di evoluzione

reward negativo per azioni sbagliate



Cose di cui parlare:
- ho finito il progetto, pseudo code con la pipeline finale
- come ho intenzione di espandere l'ambiente (porte, altri tipi di celle, parcelle che portano più score di altre, cose non legate allo score)
- come ho intenzione di eseguire gli esperimenti (no desire triggering per learning, o score più alto in periodo di tempo, o massimo numero di chiamate) (probabilmente no perception generation dopo la prima funzione)
- magari qualche esempio per mostrare lo user generated desire
- chiedere riguardo a spesa per avere una stima più accurata di quanto costa il servizio così da potermi regolare su numero/tipo esperimenti
- capire cosa c'è di interessante a capire come avviene software evolution, capire se può essere interessante la struttura in sé

Note su incontro:
complessità che aumenta: anche due agenti
5 esperimenti per ogni tipo
analisi dell'evoluzione durante i vari step
analisi di codice applicato a scenari differenti dallo scenario della generazione (più complessi)
esperimenti con più agenti e analisi di evoluzione con più agenti (o con agente singolo applicato poi con più agenti)